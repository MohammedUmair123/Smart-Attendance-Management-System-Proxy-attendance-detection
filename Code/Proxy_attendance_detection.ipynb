{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ae9663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    try:\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except:\n",
    "        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "def draw_prediction(img, classes, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    label = str(classes[class_id])\n",
    "    color = COLORS[class_id]\n",
    "    cv2.rectangle(img, (x, y), (x_plus_w, y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x-10, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "def detect_and_display(image_path, classes, config_path, weights_path):\n",
    "    # Read input image\n",
    "    image = cv2.imread(image_path)\n",
    "    Width, Height = image.shape[1], image.shape[0]\n",
    "    scale = 0.00392\n",
    "\n",
    "    # Load YOLOv4\n",
    "    net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "    # Prepare image for YOLO\n",
    "    blob = cv2.dnn.blobFromImage(image, scale, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Forward pass and get output layers\n",
    "    outs = net.forward(get_output_layers(net))\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    conf_threshold = 0.5\n",
    "    nms_threshold = 0.4\n",
    "\n",
    "    # Process detections\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > conf_threshold and class_id == person_class_index:\n",
    "                center_x = int(detection[0] * Width)\n",
    "                center_y = int(detection[1] * Height)\n",
    "                w = int(detection[2] * Width)\n",
    "                h = int(detection[3] * Height)\n",
    "                x = center_x - w // 2\n",
    "                y = center_y - h // 2\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, w, h])\n",
    "                \n",
    "    # Apply non-maximum suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    # Count total persons detected\n",
    "    total_persons = len(indices)\n",
    "\n",
    "    # Display total persons detected\n",
    "    persons_label.config(text=f\"Total persons detected: {total_persons}\")\n",
    "\n",
    "    # Display the output image with bounding boxes around persons\n",
    "    image_with_boxes = image.copy()\n",
    "    for i in indices:\n",
    "        box = boxes[i]\n",
    "        x, y, w, h = box\n",
    "        class_id = class_ids[i]\n",
    "        confidence = confidences[i]\n",
    "        draw_prediction(image_with_boxes, classes, class_id, confidence, round(x), round(y), round(x + w), round(y + h))\n",
    "\n",
    "    # Convert image to PIL format and resize\n",
    "    image_with_boxes = cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB)\n",
    "    image_with_boxes = Image.fromarray(image_with_boxes)\n",
    "    image_with_boxes = image_with_boxes.resize((250, 250))  # Resize detected image\n",
    "    image_with_boxes = ImageTk.PhotoImage(image_with_boxes)\n",
    "\n",
    "    # Update the displayed image\n",
    "    detected_image_label.config(image=image_with_boxes)\n",
    "    detected_image_label.image = image_with_boxes\n",
    "\n",
    "    # Resize uploaded image and display\n",
    "    uploaded_image = Image.open(image_path)\n",
    "    uploaded_image = uploaded_image.resize((250, 250))  # Resize uploaded image\n",
    "    uploaded_image = ImageTk.PhotoImage(uploaded_image)\n",
    "    uploaded_image_label.config(image=uploaded_image)\n",
    "    uploaded_image_label.image = uploaded_image\n",
    "\n",
    "def browse_image():\n",
    "    filename = filedialog.askopenfilename()\n",
    "    if filename:\n",
    "        detect_and_display(filename, classes, config_path, weights_path)\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Person Detection\")\n",
    "root.geometry(\"1200x700\")  # Increased height to accommodate the headings\n",
    "\n",
    "# Load background image\n",
    "background_image_path = 'pic6.jpg'\n",
    "background_image = Image.open(background_image_path)\n",
    "background_image = ImageTk.PhotoImage(background_image.resize((1200, 700)))  # Resize background image to match root window size\n",
    "\n",
    "background_label = tk.Label(root, image=background_image)\n",
    "background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "# Define your YOLOv4 file paths here\n",
    "class_path = 'coco.names'\n",
    "config_path = 'yolov4.cfg'\n",
    "weights_path = 'yolov4.weights'\n",
    "\n",
    "# Load classes\n",
    "with open(class_path, 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Filter classes to include only 'person'\n",
    "person_class_index = classes.index('person')\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# Browse image button\n",
    "browse_button = tk.Button(root, text=\"Browse Image\", command=browse_image, bg=\"#008CBA\", fg=\"white\", font=(\"Helvetica\", 14))\n",
    "browse_button.place(relx=0.5, rely=0.1, anchor=tk.CENTER)\n",
    "\n",
    "# Uploaded image heading\n",
    "uploaded_image_heading = tk.Label(root, text=\"Uploaded Image\", font=(\"Helvetica\", 14))\n",
    "uploaded_image_heading.place(relx=0.2, rely=0.3, anchor=tk.CENTER)\n",
    "\n",
    "# Detected image heading\n",
    "detected_image_heading = tk.Label(root, text=\"Detected Image\", font=(\"Helvetica\", 14))\n",
    "detected_image_heading.place(relx=0.75, rely=0.3, anchor=tk.CENTER)\n",
    "\n",
    "# Uploaded image label\n",
    "uploaded_image_label = tk.Label(root)\n",
    "uploaded_image_label.place(relx=0.2, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "# Detected image label\n",
    "detected_image_label = tk.Label(root)\n",
    "detected_image_label.place(relx=0.75, rely=0.6, anchor=tk.CENTER)\n",
    "\n",
    "# Total persons detected label\n",
    "persons_label = tk.Label(root, text=\"Total persons detected: 0\", font=(\"Helvetica\", 16))\n",
    "persons_label.place(relx=0.5, rely=0.9, anchor=tk.CENTER)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1c54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
